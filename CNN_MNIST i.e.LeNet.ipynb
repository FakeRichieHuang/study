{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25166579",
   "metadata": {},
   "source": [
    "CNN卷积神经网络处理MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e4146f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义CNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 定义卷积层\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
    "        #上方输入1通道，输出6通道 1*28*28 -> 6\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n",
    "        #上方输入6通道，输出16通道 6 -> 16\n",
    "        #conv2d函数详解\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "        #in_channels：输入通道数\n",
    "        #out_channels：输出通道数\n",
    "        #kernel_size：卷积核大小,如果是整数，则表示卷积核的高和宽相同；如果是元组，则表示卷积核的高和宽分别为元组的两个元素\n",
    "        #stride：步长，默认为1，整数则代表步长相同；元组则代表高和宽的步长分别为元组的两个元素\n",
    "        #padding：填充，默认为0\n",
    "\n",
    "        #定义全连接层\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        #上方输入16*5*5通道，输出120通道\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        #上方输入120通道，输出84通道\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "        #上方输入84通道，输出num_classes通道\n",
    "\n",
    "    # 定义前向传播\n",
    "    def forward(self, x):\n",
    "        # 卷积层1+激活+池化\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.avg_pool2d(x, kernel_size=2)\n",
    "        # 卷积层2+激活+池化\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.avg_pool2d(x, kernel_size=2)\n",
    "        # 展平\n",
    "        x = torch.flatten(x,start_dim=1)  #将16*5*5的特征图展平为一维向量\n",
    "        # 全连接层1+激活\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 全连接层2+激活\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # 全连接层3\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)  # 使用log_softmax作为输出激活函数\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9755059c",
   "metadata": {},
   "source": [
    "训练与测试函数（同SimpleNN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a3f2cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练函数\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "# args:一般是一个包含超参数的对象或命名空间（如batch_size, epochs等），用于控制训练过程\n",
    "# model: 定义的神经网络模型\n",
    "# device: 设备（CPU或GPU），用于将数据和模型移动到相应的设备上\n",
    "# train_loader: 数据加载器，用于加载训练数据，包含训练数据的批次，用于迭代访问每个batch\n",
    "# optimizer: 优化器，用于更新模型参数（如SGD, Adam等）\n",
    "# epoch: 当前训练的轮数，用于记录训练进度\n",
    "    model.train()  # 设置模型为训练模式，pytorch有train和eval两种模式，train模式会启用dropout和batch normalization等训练时特有的操作\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):#batch_idx是批次索引，data是输入数据，target是目标标签\n",
    "        data, target = data.to(device), target.to(device)  # 将数据和目标移动到设备上\n",
    "        optimizer.zero_grad()  # 清除梯度\n",
    "        output = model(data)  # 前向传播,output是模型的输出(预测结果)\n",
    "        loss = F.nll_loss(output, target)  # 计算损失(预测值与真实标签的差值),F.nll_loss是负对数似然损失函数，适用于多分类问题\n",
    "        loss.backward()  # loss反向传播\n",
    "        optimizer.step()  # l利用计算得到参数更新梯度\n",
    "\n",
    "#定义测试函数\n",
    "def test(model, device, test_loader):\n",
    "    #model: 定义的神经网络模型\n",
    "    #device: 设备（CPU或GPU），用于将数据和模型移动到相应的设备上\n",
    "    #test_loader: 数据加载器，用于加载测试数据，包含测试数据的批次，用于迭代访问每个batch\n",
    "    model.eval()  # 设置模型为评估模式，pytorch有train和eval两种模式，eval模式会禁用dropout和batch normalization等训练时特有的操作\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # 在测试时不需要计算梯度\n",
    "        for data, target in test_loader:  # 遍历测试数据\n",
    "            data, target = data.to(device), target.to(device)  # 将数据和目标移动到设备上\n",
    "            output = model(data)  # 前向传播\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # 计算损失，reduction='sum'表示对所有样本的损失\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # 获取预测结果，pred是一个张量，包含每个样本的预测类别\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()  # 计算正确预测的数量，target.view_as(pred)将target的形状调整为与pred相同，便于比较\n",
    "    test_loss /= len(test_loader.dataset)  # 计算平均损失\n",
    "\n",
    "    print('='* 50)\n",
    "    print(\"Evaluation Results:\")\n",
    "    print(f\"Average loss: {test_loss:.4f}\")\n",
    "    print(f\"Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.2f}%)\")\n",
    "    print('='* 50)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982dc134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#模型运行\n",
    "epochs = 15 # 训练轮数\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 检查是否有可用的GPU\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93bc709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# 定义优化器\n",
    "model = LeNet().to(device)  # 实例化模型并移动到设备上\n",
    "optimizer = optim.Adadelta(model.parameters())  # 使用Adadelta优化器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb1d297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 115kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:07<00:00, 228kB/s] \n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.18MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "# 定义数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # 对图像进行归一化处理\n",
    "])  \n",
    "\n",
    "dataset1 = datasets.MNIST(root='./data', download=True, train=True,  transform=transform)  # 训练集\n",
    "dataset2 = datasets.MNIST(root='./data', train=False,  download=True, transform=transform)  # 测试集\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size=64, shuffle=True)  # 训练数据加载器\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=1000, shuffle=False)  # 测试数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af7d40e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5496b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Evaluation Results:\n",
      "Average loss: 0.0628\n",
      "Accuracy: 9808/10000 (98.08%)\n",
      "==================================================\n",
      "Epoch 1 completed in 8.10 seconds for training and 0.97 seconds for testing.\n",
      "==================================================\n",
      "Evaluation Results:\n",
      "Average loss: 0.0539\n",
      "Accuracy: 9822/10000 (98.22%)\n",
      "==================================================\n",
      "Epoch 2 completed in 7.48 seconds for training and 0.90 seconds for testing.\n",
      "==================================================\n",
      "Evaluation Results:\n",
      "Average loss: 0.0362\n",
      "Accuracy: 9903/10000 (99.03%)\n",
      "==================================================\n",
      "Epoch 3 completed in 7.53 seconds for training and 0.90 seconds for testing.\n",
      "==================================================\n",
      "Evaluation Results:\n",
      "Average loss: 0.0496\n",
      "Accuracy: 9848/10000 (98.48%)\n",
      "==================================================\n",
      "Epoch 4 completed in 7.52 seconds for training and 0.91 seconds for testing.\n",
      "==================================================\n",
      "Evaluation Results:\n",
      "Average loss: 0.0354\n",
      "Accuracy: 9893/10000 (98.93%)\n",
      "==================================================\n",
      "Epoch 5 completed in 7.29 seconds for training and 0.91 seconds for testing.\n",
      "==================================================\n",
      "Evaluation Results:\n",
      "Average loss: 0.0408\n",
      "Accuracy: 9899/10000 (98.99%)\n",
      "==================================================\n",
      "Epoch 6 completed in 7.38 seconds for training and 0.90 seconds for testing.\n",
      "==================================================\n",
      "Evaluation Results:\n",
      "Average loss: 0.0347\n",
      "Accuracy: 9905/10000 (99.05%)\n",
      "==================================================\n",
      "Epoch 7 completed in 7.50 seconds for training and 0.89 seconds for testing.\n",
      "==================================================\n",
      "Evaluation Results:\n",
      "Average loss: 0.0348\n",
      "Accuracy: 9890/10000 (98.90%)\n",
      "==================================================\n",
      "Epoch 8 completed in 7.40 seconds for training and 0.91 seconds for testing.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time() #记录开始时间\n",
    "    train([],model,device,train_loader,optimizer,epoch)  # 训练模型\n",
    "    train_time = time.time()\n",
    "    test(model, device, test_loader)  # 测试模型\n",
    "    test_time = time.time()\n",
    "    train_duration = train_time - start_time\n",
    "    test_duration = test_time - train_time\n",
    "    print(f\"Epoch {epoch} completed in {train_duration:.2f} seconds for training and {test_duration:.2f} seconds for testing.\")\n",
    "# --- END OF RECENT EDITS ---\n",
    "# --- IGNORE ---\n",
    "# --- END OF IGNORE ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
